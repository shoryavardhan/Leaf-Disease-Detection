{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## IMPORTING LIBRARIES ################################################\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mahotas as mt\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/khanna/Desktop/54_ML_in_agricultural_domain/Dataset/\"\n",
    "img_files = os.listdir(ds_path)\n",
    "vector_1= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### FOR PREPROCESSING ########################################################\n",
    "\n",
    "def create_dataset():\n",
    "    names = ['area','perimeter','physiological_length','physiological_width',\\\n",
    "             'aspect_ratio','rectangularity','circularity', \\\n",
    "             'mean_r','mean_g','mean_b','stddev_r','stddev_g','stddev_b', \\\n",
    "             'contrast','correlation','inverse_difference_moments','entropy'\n",
    "            ]\n",
    "    df = pd.DataFrame([], columns=names)\n",
    "    for i in range(1,600):\n",
    "        imgpath = ds_path + \"/\" +str(i)+\".jpg\"\n",
    "        main_img = cv2.imread(imgpath)\n",
    "        if(main_img is not None):\n",
    "            img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB)         \n",
    "            gs = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            blur = cv2.GaussianBlur(gs, (25,25),0)\n",
    "            ret_otsu,im_bw_otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "            kernel = np.ones((50,50),np.uint8)\n",
    "            closing = cv2.morphologyEx(im_bw_otsu, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            #Shape features\n",
    "            contours,hierarchy = cv2.findContours(closing,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnt = contours[0]\n",
    "            M = cv2.moments(cnt)\n",
    "            area = cv2.contourArea(cnt)\n",
    "            perimeter = cv2.arcLength(cnt,True)\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w)/h\n",
    "            if(area):\n",
    "                rectangularity = w*h/area\n",
    "                circularity = ((perimeter)**2)/area\n",
    "\n",
    "            #Color features\n",
    "            red_channel = img[:,:,0]\n",
    "            green_channel = img[:,:,1]\n",
    "            blue_channel = img[:,:,2]\n",
    "            blue_channel[blue_channel == 255] = 0\n",
    "            green_channel[green_channel == 255] = 0\n",
    "            red_channel[red_channel == 255] = 0\n",
    "\n",
    "            red_mean = np.mean(red_channel)\n",
    "            green_mean = np.mean(green_channel)\n",
    "            blue_mean = np.mean(blue_channel)\n",
    "\n",
    "            red_std = np.std(red_channel)\n",
    "            green_std = np.std(green_channel)\n",
    "            blue_std = np.std(blue_channel)\n",
    "\n",
    "            #Texture features\n",
    "            #used to find textures in the pictures\n",
    "            textures = mt.features.haralick(gs)\n",
    "            ht_mean = textures.mean(axis=0)\n",
    "            contrast = ht_mean[1]\n",
    "            correlation = ht_mean[2]\n",
    "            inverse_diff_moments = ht_mean[4]\n",
    "            entropy = ht_mean[8]\n",
    "\n",
    "            vector = [area,perimeter,w,h,aspect_ratio,rectangularity,circularity,\\\n",
    "                      red_mean,green_mean,blue_mean,red_std,green_std,blue_std,\\\n",
    "                      contrast,correlation,inverse_diff_moments,entropy\n",
    "                     ]\n",
    "\n",
    "            df_temp = pd.DataFrame([vector],columns=names)\n",
    "            df = df.append(df_temp)\n",
    "    return df\n",
    "\n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def vector_calc():\n",
    "    f=input()\n",
    "    imgpath = ds_path + \"/\"+str(f)+\".jpg\"\n",
    "    print(imgpath)\n",
    "    main_img = cv2.imread(imgpath)\n",
    "#     print(\"1\")\n",
    "    if(main_img is not None):\n",
    "        img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB) \n",
    "        gs = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)  \n",
    "        blur = cv2.GaussianBlur(gs, (25,25),0)\n",
    "        ret_otsu,im_bw_otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        kernel = np.ones((50,50),np.uint8)\n",
    "        closing = cv2.morphologyEx(im_bw_otsu, cv2.MORPH_CLOSE, kernel)\n",
    "        #Shape features\n",
    "        contours,hierarchy = cv2.findContours(closing,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        M = cv2.moments(cnt)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt,True)\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = float(w)/h\n",
    "#         print(\"2\")\n",
    "        if(area):\n",
    "#             print(\"3\")\n",
    "            rectangularity = w*h/area\n",
    "            circularity = ((perimeter)**2)/area\n",
    "        #Color features\n",
    "#         print(\"4\")\n",
    "        red_channel = img[:,:,0]\n",
    "        green_channel = img[:,:,1]\n",
    "        blue_channel = img[:,:,2]\n",
    "        blue_channel[blue_channel == 255] = 0\n",
    "        green_channel[green_channel == 255] = 0\n",
    "        red_channel[red_channel == 255] = 0\n",
    "        red_mean = np.mean(red_channel)\n",
    "        green_mean = np.mean(green_channel)\n",
    "        blue_mean = np.mean(blue_channel)\n",
    "        red_std = np.std(red_channel)\n",
    "        green_std = np.std(green_channel)\n",
    "        blue_std = np.std(blue_channel)\n",
    "        #Texture features\n",
    "        #used to find textures in the pictures\n",
    "        textures = mt.features.haralick(gs)\n",
    "        ht_mean = textures.mean(axis=0)\n",
    "        contrast = ht_mean[1]\n",
    "        correlation = ht_mean[2]\n",
    "        inverse_diff_moments = ht_mean[4]\n",
    "        entropy = ht_mean[8]\n",
    "        global vector_1\n",
    "        vector_1 = [area,perimeter,w,h,aspect_ratio,rectangularity,circularity,\\\n",
    "                  red_mean,green_mean,blue_mean,red_std,green_std,blue_std,\\\n",
    "                  contrast,correlation,inverse_diff_moments,entropy\n",
    "                 ]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = create_dataset()\n",
    "# dataset.to_csv(\"train_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_calc()\n",
    "print(vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## DATASET PREPARATION #############################################\n",
    "\n",
    "dataset = pd.read_csv(\"trained_features.csv\")\n",
    "dataset1 = pd.read_csv(\"bp_train_features.csv\")\n",
    "dataset2 = pd.read_csv(\"p_train_features.csv\")\n",
    "dataset3= pd.read_csv(\"t_train_features.csv\")\n",
    "breakpoints = [1,80,81,200,201,600]\n",
    "breakpoints1 = [1,40,41,80]\n",
    "breakpoints2 = [1,40,41,80,81,120]\n",
    "breakpoints3 = [1,40,41,80,81,120,121,160,161,200,201,240,241,280,281,320,321,360,361,399]\n",
    "maindir = \"/home/khanna/Desktop/Major2\"\n",
    "ds_path = maindir + \"/M\"\n",
    "img_files = os.listdir(ds_path)\n",
    "svm_clf = None\n",
    "knn = None\n",
    "knn_bp = None\n",
    "knn_p = None\n",
    "knn_t = None\n",
    "accuracy_bp = None\n",
    "accuracy_p = None\n",
    "accuracy_t = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for j in range(1,600):\n",
    "    target_num = j\n",
    "    #print(target_num)\n",
    "    flag = 0\n",
    "    i = 0 \n",
    "    for i in range(0,len(breakpoints),2):\n",
    "        if((target_num >= breakpoints[i]) and (target_num <= breakpoints[i+1])):\n",
    "            flag = 1\n",
    "            break\n",
    "    if(flag==1):\n",
    "        target = int((i/2))\n",
    "        target_list.append(target)\n",
    "y = np.asarray(target_list)\n",
    "X = dataset.iloc[:,1:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 142)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### MODELS FOR LEAF IDENTIFICATION #######################################\n",
    "def svm_gs():\n",
    "    print(\"Starting....\")\n",
    "    clf = svm.SVC()\n",
    "    print(\"Starting....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Starting....\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Starting....\")\n",
    "    from sklearn import metrics\n",
    "    print(\"Starting....\")\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = [{'kernel': ['rbf'],\n",
    "                   'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5],\n",
    "                   'C': [1, 10, 100, 1000]},\n",
    "                  {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "                 ]\n",
    "    print(\"Starting....\")\n",
    "    global svm_clf\n",
    "    print(\"Starting....\")\n",
    "    svm_clf = GridSearchCV(svm.SVC(decision_function_shape='ovr'), parameters, cv=5)\n",
    "    print(\"Starting....1\")\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    print(\"Starting....2\")\n",
    "    y_pred_svm = svm_clf.predict(X_test)\n",
    "    print(\"Starting....3\")\n",
    "    #print(\"Grid Search Accuracy:\",metrics.accuracy_score(y_test, y_pred_svm))\n",
    "    #print(y_pred_svm)\n",
    "    #print(X_test)\n",
    "\n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def knn():\n",
    "    print(\"Starting....\")\n",
    "    global knn;\n",
    "    knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_test, y_test) \n",
    "    y_pred=knn.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    #print (\"KNN Accuracy:\", accuracy) \n",
    "    \n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def svm_calc(array):\n",
    "    global svm_clf\n",
    "    ans=svm_clf.predict(array)\n",
    "    return ans\n",
    "def knn_calc(array):\n",
    "    global knn\n",
    "    ans= knn.predict(array)\n",
    "    return ans\n",
    "\n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def identify(ans): \n",
    "    if(ans==0):\n",
    "      str =\"Bell Pepper\"\n",
    "    elif(ans==1):\n",
    "      str=\"Potato\" \n",
    "    else:\n",
    "      str=\"Tomato\"\n",
    "    return str\n",
    "\n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def predict_ans(dis):\n",
    "    if(dis==0):    \n",
    "        str = \"Diseased Bell Pepper with Bacterial Spot\"\n",
    "    elif(dis==1):    \n",
    "        str = \"Healthy Bell Pepper\"\n",
    "    elif(dis==2):    \n",
    "        str = \"Diseased Potato with Early Blight\"\n",
    "    elif(dis==3):    \n",
    "        str = \"Healthy Potato\"\n",
    "    elif(dis==4):    \n",
    "        str = \"Diseased Potato with Late Blight\"\n",
    "    elif(dis==5):    \n",
    "        str = \"Diseased Tomato with Target Spot\"\n",
    "    elif(dis==6):    \n",
    "        str = \"Diseased Tomato with Mosaic Virus\"\n",
    "    elif(dis==7):    \n",
    "        str = \"Diseased Tomato with Yellow Leaf Curl Virus\"\n",
    "    elif(dis==8):    \n",
    "        str = \"Diseased Tomato with Bacterial Spot\"\n",
    "    elif(dis==9):    \n",
    "        str = \"Diseased Tomato with Early Blight\"\n",
    "    elif(dis==10):    \n",
    "        str = \"Healthy Tomato\"\n",
    "    elif(dis==11):    \n",
    "        str = \"Diseased Tomato with Late Blight\"\n",
    "    elif(dis==12):    \n",
    "        str = \"Diseased Tomato with Leaf Mold\"\n",
    "    elif(dis==13):    \n",
    "        str = \"Diseased Tomato with Seporia Leaf Spot\"\n",
    "    elif(dis==14):    \n",
    "        str = \"Diseased Tomato with Spider Mites\"\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## PREPARING MODEL FOR LEAF IDENTIFICATION ####################################\n",
    "\n",
    "# svm_gs()\n",
    "knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### TESTING FOR SINGLE ITEM ################################################\n",
    "\n",
    "X_query = [vector_1]\n",
    "\n",
    "choice =2\n",
    "if(choice == 1):\n",
    "    ans = svm_calc(X_query)\n",
    "elif(choice == 2):\n",
    "    ans = knn_calc(X_query)\n",
    "mainAns= identify(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## MODELS FOR DISEASE DETECTION ########################################\n",
    "\n",
    "def for_bp():\n",
    "    target_list = []\n",
    "    for j in range(1,81):\n",
    "        target_num = j\n",
    "        #print(target_num)\n",
    "        flag = 0\n",
    "        i = 0 \n",
    "        for i in range(0,len(breakpoints1),2):\n",
    "            if((target_num >= breakpoints1[i]) and (target_num <= breakpoints1[i+1])):\n",
    "                flag = 1\n",
    "                break\n",
    "        if(flag==1):\n",
    "            target = int((i/2))\n",
    "            target_list.append(target)\n",
    "    y = np.array(target_list)\n",
    "    X = dataset1.iloc[:,1:]\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 142)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    global knn_bp\n",
    "    knn_bp = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
    "    global accuracy_bp\n",
    "    accuracy_bp = knn_bp.score(X_test, y_test) \n",
    "    y_pred=knn_bp.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    #from sklearn import metrics\n",
    "    #print(\"KNN Metrics:\")\n",
    "    #print(metrics.classification_report(y_test, y_pred))\n",
    "    #print (\"KNN Accuracy:\", accuracy_bp) \n",
    "\n",
    "#____________________________________________________________________________________________________________\n",
    "\n",
    "def for_p():\n",
    "    target_list = []\n",
    "    for j in range(1,121):\n",
    "        target_num = j\n",
    "        #print(target_num)\n",
    "        flag = 0\n",
    "        i = 0 \n",
    "        for i in range(0,len(breakpoints2),2):\n",
    "            if((target_num >= breakpoints2[i]) and (target_num <= breakpoints2[i+1])):\n",
    "                flag = 1\n",
    "                break\n",
    "        if(flag==1):\n",
    "            target = int((i/2))\n",
    "            target_list.append(target)\n",
    "    y = np.array(target_list)\n",
    "    X = dataset2.iloc[:,1:]\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 142)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    global knn_p\n",
    "    knn_p = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
    "    global accuracy_p\n",
    "    accuracy_p = knn_p.score(X_test, y_test) \n",
    "    y_pred=knn_p.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    #from sklearn import metrics\n",
    "    #print(\"KNN Metrics:\")\n",
    "    #print(metrics.classification_report(y_test, y_pred))\n",
    "    #print (\"KNN Accuracy:\", accuracy_p)\n",
    "    \n",
    "#____________________________________________________________________________________________________________\n",
    "        \n",
    "def for_t():\n",
    "    target_list = []\n",
    "    for j in range(1,401):\n",
    "        target_num = j\n",
    "        #print(target_num)\n",
    "        flag = 0\n",
    "        i = 0 \n",
    "        for i in range(0,len(breakpoints3),2):\n",
    "            if((target_num >= breakpoints3[i]) and (target_num <= breakpoints3[i+1])):\n",
    "                flag = 1\n",
    "                break\n",
    "        if(flag==1):\n",
    "            target = int((i/2))\n",
    "            target_list.append(target)\n",
    "    y = np.array(target_list)\n",
    "    X = dataset3 .iloc[:,1:]\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 142)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    global knn_t\n",
    "    knn_t = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)\n",
    "    global accuracy_t\n",
    "    accuracy_t = knn_t.score(X_test, y_test) \n",
    "    y_pred=knn_t.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    from sklearn import metrics\n",
    "    #print(\"KNN Metrics:\")\n",
    "    #print(metrics.classification_report(y_test, y_pred))\n",
    "    #print (\"KNN Accuracy:\", accuracy_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### PREPARING MODEL FOR DISEASE CLASSIFICATION ###################################\n",
    "\n",
    "# for_bp() \n",
    "# for_p()\n",
    "# for_t()    \n",
    "\n",
    "if(ans==0):    \n",
    "    ans1 = knn_bp.predict(X_query)\n",
    "    dis = ans1\n",
    "    acc= accuracy_bp\n",
    "elif(ans==1):\n",
    "    ans2 = knn_p.predict(X_query)\n",
    "    dis = ans2 + 2\n",
    "    acc= accuracy_p\n",
    "elif(ans==2):\n",
    "    ans3 = knn_t.predict(X_query)\n",
    "    dis = ans3 + 6\n",
    "    acc= accuracy_t\n",
    "\n",
    "string = predict_ans(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################################# ANSWER #####################################################\n",
    "\n",
    "print(\"Leaf Prediction Result :\")\n",
    "print(\"This is a \"+ mainAns +\" leaf\")\n",
    "print(\" \")\n",
    "print(\"Disease Classification Result :\")\n",
    "print(\"This is a \"+string )\n",
    "print(\" \")\n",
    "print(\"Accuracy :\")\n",
    "print(acc*100 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
